{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서의 조작(Manipulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인덱싱(Indexing) \n",
    "- numpy처럼 인덱싱 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor(1)\n",
      "tensor([1, 2])\n",
      "tensor([1, 3])\n",
      "tensor([2, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1,2],[3,4]])\n",
    "print(x)\n",
    "print(x[0, 0]) # 0행 0열\n",
    "\n",
    "print(x[0]) # 0행의 값 불러옴\n",
    "\n",
    "print(x[:, 0]) # 0열의 값 불러옴\n",
    "print(x[:, 1]) # 1열의 값 불러옴\n",
    "\n",
    "t = torch.tensor([[1, 2], [3, 4]])\n",
    "print(t[0, 1])  # 출력: 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D 텐서\n",
    "t = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "])\n",
    "\n",
    "# (1) 첫 번째 행의 모든 열\n",
    "print(t[0, :])  # 출력: [1, 2, 3]\n",
    "\n",
    "# (2) 모든 행의 두 번째 열\n",
    "print(t[:, 1])  # 출력: [2, 5, 8]\n",
    "\n",
    "# (3) 첫 번째 행과 두 번째 열의 값\n",
    "print(t[0, 1])  # 출력: 2\n",
    "\n",
    "# (4) 첫 번째와 두 번째 행의 두 번째와 세 번째 열\n",
    "print(t[0:2, 1:3])  # 출력: [[2, 3], [5, 6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서의 크기나 모양을 변경\n",
    "- `torch.view()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.2988,  0.3119,  0.8505,  1.1979,  0.5643],\n",
      "        [ 1.1009,  0.6904,  0.1232,  0.6124,  1.0480],\n",
      "        [-0.3335,  1.9397, -0.3380, -0.8672, -0.2809],\n",
      "        [ 1.8433, -0.9317,  0.3486,  0.0256, -0.4010]])\n",
      "tensor([ 2.2988,  0.3119,  0.8505,  1.1979,  0.5643,  1.1009,  0.6904,  0.1232,\n",
      "         0.6124,  1.0480, -0.3335,  1.9397, -0.3380, -0.8672, -0.2809,  1.8433,\n",
      "        -0.9317,  0.3486,  0.0256, -0.4010])\n",
      "tensor([[ 2.2988,  0.3119,  0.8505,  1.1979],\n",
      "        [ 0.5643,  1.1009,  0.6904,  0.1232],\n",
      "        [ 0.6124,  1.0480, -0.3335,  1.9397],\n",
      "        [-0.3380, -0.8672, -0.2809,  1.8433],\n",
      "        [-0.9317,  0.3486,  0.0256, -0.4010]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4,5)\n",
    "print(x)\n",
    "\n",
    "y = x.view(20)\n",
    "print(y)\n",
    "\n",
    "z = y.view(5, -1) # -1은 자동으로\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서의 숫자값 얻기\n",
    "- `torch.item()` : 스칼라 값 하나만 존재해야 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5054])\n",
      "0.5053906440734863\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 차원 축소(제거)\n",
    "- `torch.squeeze()` : 크기가 1인 차원을 줄여줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1872, 0.3698, 0.0337]],\n",
      "\n",
      "        [[0.1201, 0.1792, 0.2698]],\n",
      "\n",
      "        [[0.1114, 0.9417, 0.2574]]])\n",
      "torch.Size([3, 1, 3])\n",
      "tensor([[0.1872, 0.3698, 0.0337],\n",
      "        [0.1201, 0.1792, 0.2698],\n",
      "        [0.1114, 0.9417, 0.2574]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1, 3, 3)\n",
    "print(x)\n",
    "print(x.shape)\n",
    "\n",
    "y = torch.squeeze(x)\n",
    "print(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 차원 증가(생성)\n",
    "- `torch.unsqueeze()` : dim설정에 따라 변경됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9856, 0.7171, 0.9319],\n",
      "         [0.4020, 0.3972, 0.2437],\n",
      "         [0.8736, 0.5690, 0.5863]],\n",
      "\n",
      "        [[0.8512, 0.6273, 0.3506],\n",
      "         [0.3335, 0.2429, 0.6819],\n",
      "         [0.1283, 0.0253, 0.6008]],\n",
      "\n",
      "        [[0.7903, 0.5933, 0.1898],\n",
      "         [0.3709, 0.2408, 0.4679],\n",
      "         [0.5221, 0.2332, 0.7500]]])\n",
      "torch.Size([3, 3, 3])\n",
      "tensor([[[[0.9856],\n",
      "          [0.7171],\n",
      "          [0.9319]],\n",
      "\n",
      "         [[0.4020],\n",
      "          [0.3972],\n",
      "          [0.2437]],\n",
      "\n",
      "         [[0.8736],\n",
      "          [0.5690],\n",
      "          [0.5863]]],\n",
      "\n",
      "\n",
      "        [[[0.8512],\n",
      "          [0.6273],\n",
      "          [0.3506]],\n",
      "\n",
      "         [[0.3335],\n",
      "          [0.2429],\n",
      "          [0.6819]],\n",
      "\n",
      "         [[0.1283],\n",
      "          [0.0253],\n",
      "          [0.6008]]],\n",
      "\n",
      "\n",
      "        [[[0.7903],\n",
      "          [0.5933],\n",
      "          [0.1898]],\n",
      "\n",
      "         [[0.3709],\n",
      "          [0.2408],\n",
      "          [0.4679]],\n",
      "\n",
      "         [[0.5221],\n",
      "          [0.2332],\n",
      "          [0.7500]]]])\n",
      "torch.Size([3, 3, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3, 3, 3)\n",
    "print(tensor)\n",
    "print(tensor.shape)\n",
    "\n",
    "ts = torch.unsqueeze(tensor, 3) # 0 가장 상위차원 -> 3 가장 하위차원\n",
    "print(ts)\n",
    "print(ts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서간 결합\n",
    "- `torch.stack()`\n",
    "  - 동일한 형식의 텐서를 새롭게 '그룹화'함 : 새로운 차원이 생성됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n",
      "[[[1, 2], [3, 4]], [[5, 6], [7, 8]]]\n",
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[5, 6],\n",
      "         [7, 8]]])\n",
      "3\n",
      "torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([1,4])\n",
    "y = torch.FloatTensor([2,5])\n",
    "z = torch.FloatTensor([3,6])\n",
    "\n",
    "# new = [x,y,z]\n",
    "# print(new)\n",
    "print(torch.stack([x,y,z]))\n",
    "# d = [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]\n",
    "# print(d)\n",
    "\n",
    "a = torch.tensor([[1, 2], [3, 4]])  # (2, 2)\n",
    "b = torch.tensor([[5, 6], [7, 8]])  # (2, 2)\n",
    "c = torch.stack([a,b])\n",
    "print(c)\n",
    "print(c.ndim)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `torch.cat()`\n",
    "  - 데이터를 하나의 텐서로 병합 : 새로운 차원 생성되지X\n",
    "  - Numpy의 stack과 유사하지만, 쌓을 dim이 존재해야 함\n",
    "  - 결합하려는 축 외에는 동일해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6],\n",
      "        [5, 6],\n",
      "        [7, 8]])\n",
      "torch.Size([5, 2])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4], [5,6]])  # (2, 2)\n",
    "b = torch.tensor([[5, 6], [7, 8]])  # (2, 2)\n",
    "c = torch.cat((a,b), dim=0) # dim은 tensor를 결합할 축 0번축: 행, 1번축: 열\n",
    "print(c)\n",
    "print(c.shape)\n",
    "print(c.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 나누기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `torch.chunk()` : 텐서를 여러개로 나눔\n",
    "  - 몇개로 나눌지를 지정\n",
    "  - 나누어 떨어지지 않는 경우, 마지막 조각이 다른 크기를 가질 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6153, 0.0925, 0.4123, 0.2625, 0.1522, 0.8222],\n",
      "        [0.7711, 0.2194, 0.6604, 0.1322, 0.5243, 0.1511],\n",
      "        [0.6870, 0.3219, 0.4820, 0.5487, 0.1508, 0.5209]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6153, 0.0925],\n",
       "         [0.7711, 0.2194],\n",
       "         [0.6870, 0.3219]]),\n",
       " tensor([[0.4123, 0.2625],\n",
       "         [0.6604, 0.1322],\n",
       "         [0.4820, 0.5487]]),\n",
       " tensor([[0.1522, 0.8222],\n",
       "         [0.5243, 0.1511],\n",
       "         [0.1508, 0.5209]]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand(3,6)\n",
    "print(tensor)\n",
    "\n",
    "# (텐서, 나눌 수, 차원(축))\n",
    "t1, t2, t3 = torch.chunk(tensor, 3, dim=1) # dim은 차원\n",
    "print(t1, t2, t3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `torch.split()` : 기능은 chunk와 비슷하지만, 나누는 방식이 다름\n",
    "  - 텐서의 크기가 몇이냐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6766, 0.0658, 0.8299, 0.0079, 0.4463, 0.4774],\n",
      "        [0.6273, 0.1408, 0.5442, 0.7057, 0.0689, 0.5901],\n",
      "        [0.5630, 0.2270, 0.4752, 0.3775, 0.9892, 0.3596]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6766, 0.0658, 0.8299],\n",
       "         [0.6273, 0.1408, 0.5442],\n",
       "         [0.5630, 0.2270, 0.4752]]),\n",
       " tensor([[0.0079, 0.4463, 0.4774],\n",
       "         [0.7057, 0.0689, 0.5901],\n",
       "         [0.3775, 0.9892, 0.3596]]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.rand(3,6)\n",
    "print(tensor)\n",
    "\n",
    "# (텐서, 나눌 수, 차원(축))\n",
    "t1, t2 = torch.split(tensor, 3, dim=1) # dim은 차원\n",
    "# dim=1이고 size=3이라면 열이 3개가 되도록 나누는 것\n",
    "t1, t2\n",
    "\n",
    "tensor = torch.rand(3,6)\n",
    "print(tensor)\n",
    "\n",
    "x = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# 크기 2로 나누기\n",
    "result_x = torch.split(x, split_size_or_sections=2, dim=0)\n",
    "print(result_x)\n",
    "\n",
    "y = torch.tensor([1, 2, 3, 4, 5])\n",
    "\n",
    "# 각각의 크기를 지정\n",
    "result_y = torch.split(x, split_size_or_sections=[2, 2, 1], dim=0)\n",
    "print(result_y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
